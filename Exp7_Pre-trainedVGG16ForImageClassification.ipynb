{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyP3PRCRaTbvhbSdKp+WE2VG"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":228},"id":"YiVBy9U4wLBS","executionInfo":{"status":"error","timestamp":1763918875686,"user_tz":-330,"elapsed":14585,"user":{"displayName":"VIRAJ BELE","userId":"00719035953066192123"}},"outputId":"94ebad92-2f5b-4255-95cc-3666fca8375b"},"outputs":[{"output_type":"stream","name":"stdout","text":["TensorFlow version: 2.19.0\n"]},{"output_type":"error","ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: 'data/train'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-4077280202.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;31m# Automatically count number of classes from folders\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0mnum_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Number of classes:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/train'"]}],"source":["# Experiment 7: Using pre-trained VGG16 for image classification\n","\n","import os\n","import matplotlib.pyplot as plt\n","import tensorflow as tf\n","from tensorflow.keras.applications import VGG16\n","from tensorflow.keras import layers, models\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","\n","print(\"TensorFlow version:\", tf.__version__)\n","\n","# -----------------------------\n","# 1. Basic configuration\n","# -----------------------------\n","img_height = 150\n","img_width = 150\n","batch_size = 32\n","\n","train_dir = \"data/train\"         # change this\n","val_dir   = \"data/validation\"    # change this\n","\n","# Automatically count number of classes from folders\n","num_classes = len(os.listdir(train_dir))\n","print(\"Number of classes:\", num_classes)\n","\n","# -----------------------------\n","# 2. Data generators\n","# -----------------------------\n","train_datagen = ImageDataGenerator(\n","    rescale=1./255,\n","    rotation_range=20,\n","    width_shift_range=0.1,\n","    height_shift_range=0.1,\n","    shear_range=0.1,\n","    zoom_range=0.1,\n","    horizontal_flip=True\n",")\n","\n","val_datagen = ImageDataGenerator(rescale=1./255)\n","\n","train_generator = train_datagen.flow_from_directory(\n","    train_dir,\n","    target_size=(img_height, img_width),\n","    batch_size=batch_size,\n","    class_mode='categorical'\n",")\n","\n","validation_generator = val_datagen.flow_from_directory(\n","    val_dir,\n","    target_size=(img_height, img_width),\n","    batch_size=batch_size,\n","    class_mode='categorical'\n",")\n","\n","print(\"Class indices:\", train_generator.class_indices)\n","\n","# -----------------------------\n","# 3. Instantiate VGG16 base\n","# -----------------------------\n","conv_base = VGG16(\n","    weights='imagenet',\n","    include_top=False,                 # remove dense classifier of VGG16\n","    input_shape=(img_height, img_width, 3)\n",")\n","\n","print(conv_base.summary())\n","\n","# Freeze convolutional base for feature extraction\n","conv_base.trainable = False\n","\n","# -----------------------------\n","# 4. Build the full model\n","# -----------------------------\n","model = models.Sequential([\n","    conv_base,\n","    layers.Flatten(),\n","    layers.Dense(256, activation='relu'),\n","    layers.Dropout(0.5),\n","    layers.Dense(num_classes, activation='softmax')\n","])\n","\n","model.compile(\n","    loss='categorical_crossentropy',\n","    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n","    metrics=['accuracy']\n",")\n","\n","print(model.summary())\n","\n","# -----------------------------\n","# 5. Train (Feature Extraction)\n","# -----------------------------\n","epochs = 10   # change as needed\n","history = model.fit(\n","    train_generator,\n","    epochs=epochs,\n","    validation_data=validation_generator\n",")\n","\n","# -----------------------------\n","# 6. Plot accuracy and loss\n","# -----------------------------\n","acc      = history.history['accuracy']\n","val_acc  = history.history['val_accuracy']\n","loss     = history.history['loss']\n","val_loss = history.history['val_loss']\n","\n","epochs_range = range(1, len(acc) + 1)\n","\n","plt.figure()\n","plt.plot(epochs_range, acc, label='Train Accuracy')\n","plt.plot(epochs_range, val_acc, label='Val Accuracy')\n","plt.xlabel('Epoch')\n","plt.ylabel('Accuracy')\n","plt.legend()\n","plt.title('Training and Validation Accuracy')\n","plt.show()\n","\n","plt.figure()\n","plt.plot(epochs_range, loss, label='Train Loss')\n","plt.plot(epochs_range, val_loss, label='Val Loss')\n","plt.xlabel('Epoch')\n","plt.ylabel('Loss')\n","plt.legend()\n","plt.title('Training and Validation Loss')\n","plt.show()\n","\n","# -----------------------------\n","# 7. OPTIONAL: Fine-tuning\n","# -----------------------------\n","# Unfreeze some top layers of VGG16\n","conv_base.trainable = True\n","\n","# Let's say we fine-tune from block5_conv1 onward\n","fine_tune_from = None\n","for i, layer in enumerate(conv_base.layers):\n","    if layer.name == 'block5_conv1':\n","        fine_tune_from = i\n","        break\n","\n","for i, layer in enumerate(conv_base.layers):\n","    if i < fine_tune_from:\n","        layer.trainable = False\n","    else:\n","        layer.trainable = True\n","\n","model.compile(\n","    loss='categorical_crossentropy',\n","    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5),  # smaller LR\n","    metrics=['accuracy']\n",")\n","\n","fine_tune_epochs = 5  # extra epochs for fine-tuning\n","\n","history_fine = model.fit(\n","    train_generator,\n","    epochs=fine_tune_epochs,\n","    validation_data=validation_generator\n",")\n","\n","# You can again plot accuracy & loss for fine-tuning if needed.\n"]}]}
