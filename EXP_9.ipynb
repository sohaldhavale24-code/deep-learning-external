{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNMQPe4MNMz6cgPKY1G3sDA"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":663},"id":"vyzVxVDcUyeN","executionInfo":{"status":"ok","timestamp":1763929655312,"user_tz":-330,"elapsed":8383,"user":{"displayName":"VIRAJ BELE","userId":"00719035953066192123"}},"outputId":"0e22cfd6-211c-4517-d0b8-c909bc430d15"},"outputs":[{"output_type":"stream","name":"stderr","text":["Device set to use cpu\n"]},{"output_type":"stream","name":"stdout","text":["It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n","\n","Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n","* Running on public URL: https://ba6acb0b03ba1c343d.gradio.live\n","\n","This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<div><iframe src=\"https://ba6acb0b03ba1c343d.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":[]},"metadata":{},"execution_count":10}],"source":["from transformers import pipeline\n","import gradio as gr\n","\n","# Load translation model with the new, more effective model\n","translator = pipeline(\"translation\", model=\"facebook/nllb-200-distilled-600M\", src_lang=\"eng_Latn\", tgt_lang=\"hin_Deva\")\n","\n","# Function to translate\n","def translate_text(text):\n","    result = translator(text)\n","    return result[0]['translation_text']\n","\n","# Create UI\n","interface = gr.Interface(\n","    fn=translate_text,\n","    inputs=gr.Textbox(lines=3, placeholder=\"Enter English text here...\"),\n","    outputs=\"text\",\n","    title=\"English to Hindi Translator using LLM\",\n","    description=\"This model uses a pre-trained Large Language Model from Hugging Face.\"\n",")\n","\n","interface.launch()"]}]}