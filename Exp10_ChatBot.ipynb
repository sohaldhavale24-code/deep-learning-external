{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyO7E6VVJwim891pQdQlbyTA"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"GMYQPGTOcBU0"},"outputs":[],"source":["# Experiment 10: Chatbot using Pre-trained Transformer Model\n","# Requirements: transformers, torch, gradio\n","\n","from transformers import pipeline\n","import gradio as gr\n","\n","# 1. Load pre-trained Transformer chatbot model\n","# Using DialoGPT-small (a conversational GPT model by Microsoft)\n","chatbot_pipeline = pipeline(\n","    \"text-generation\",\n","    model=\"microsoft/DialoGPT-small\"\n",")\n","\n","# 2. Define chatbot response function\n","def generate_response(user_input):\n","    if not user_input or user_input.strip() == \"\":\n","        return \"Please say something, I'm listening ðŸ™‚\"\n","\n","    # Generate response using the model\n","    result = chatbot_pipeline(\n","        user_input,\n","        max_new_tokens=50,       # Max number of tokens to generate for the reply\n","        num_return_sequences=1,\n","        do_sample=True,\n","        temperature=0.6,         # Slightly reduced creativity for more focused output\n","        top_k=50,\n","        top_p=0.95,\n","        truncation=True          # Explicitly enable truncation for long inputs\n","    )\n","\n","    # Model returns continuation of the prompt (input + reply)\n","    full_text = result[0][\"generated_text\"]\n","\n","    # Simple way: remove the original user input from the beginning\n","    if full_text.startswith(user_input):\n","        reply = full_text[len(user_input):].strip()\n","    else:\n","        reply = full_text.strip()\n","\n","    # Fallback\n","    if reply == \"\":\n","        reply = \"I am not sure what to say, but I'm learning! ðŸ¤–\"\n","\n","    return reply\n","\n","\n","# 3. Create Gradio Interface\n","iface = gr.Interface(\n","    fn=generate_response,\n","    inputs=gr.Textbox(lines=2, placeholder=\"Type your message here...\"),\n","    outputs=\"text\",\n","    title=\"Transformer-based Chatbot (DialoGPT)\",\n","    description=\"A simple chatbot built using a pre-trained Transformer model (DialoGPT-small) from Hugging Face.\"\n",")\n","\n","# 4. Launch the app\n","if __name__ == \"__main__\":\n","    # For Colab, it's good practice to explicitly set share=True and debug=True\n","    iface.launch(share=True, debug=True)\n"]},{"cell_type":"code","source":[],"metadata":{"id":"_KvcpLmAcFQE"},"execution_count":null,"outputs":[]}]}
