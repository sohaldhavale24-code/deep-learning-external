{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPuJoVKQNRawjE1RYjGpP64"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qweQn8KGH70k","executionInfo":{"status":"ok","timestamp":1763908332602,"user_tz":-330,"elapsed":60539,"user":{"displayName":"VIRAJ BELE","userId":"00719035953066192123"}},"outputId":"b6fa3fa1-ac2d-4401-951f-e4bbe348498c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n","\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(**kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/8\n","\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 12ms/step - accuracy: 0.7666 - loss: 0.7886 - val_accuracy: 0.9595 - val_loss: 0.1490\n","Epoch 2/8\n","\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.9423 - loss: 0.1987 - val_accuracy: 0.9722 - val_loss: 0.1026\n","Epoch 3/8\n","\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 0.9581 - loss: 0.1382 - val_accuracy: 0.9745 - val_loss: 0.0839\n","Epoch 4/8\n","\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - accuracy: 0.9673 - loss: 0.1094 - val_accuracy: 0.9768 - val_loss: 0.0777\n","Epoch 5/8\n","\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.9753 - loss: 0.0874 - val_accuracy: 0.9775 - val_loss: 0.0732\n","Epoch 6/8\n","\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.9766 - loss: 0.0752 - val_accuracy: 0.9802 - val_loss: 0.0642\n","Epoch 7/8\n","\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - accuracy: 0.9791 - loss: 0.0678 - val_accuracy: 0.9798 - val_loss: 0.0671\n","Epoch 8/8\n","\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.9816 - loss: 0.0584 - val_accuracy: 0.9825 - val_loss: 0.0595\n","Test accuracy: 0.9811999797821045\n","Used hyperparameters -> lr: 0.0005 , batch_size: 128 , epochs: 8\n"]}],"source":["# Step 1: Import libraries\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras import layers\n","\n","# Step 2: Load and normalize MNIST dataset\n","(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n","x_train = x_train.astype(\"float32\") / 255.0\n","x_test  = x_test.astype(\"float32\") / 255.0\n","\n","# Step 3: Choose hyperparameters (you can change these values)\n","learning_rate = 0.0005   # try 0.001 or 0.0001\n","batch_size = 128         # try 32, 64, 256\n","epochs = 8               # try 5, 10, 15\n","\n","# Step 4: Build model with dropout (to reduce overfitting)\n","model = keras.Sequential([\n","    layers.Flatten(input_shape=(28, 28)),\n","    layers.Dense(256, activation=\"relu\"),\n","    layers.Dropout(0.3),                # dropout rate is a hyperparameter\n","    layers.Dense(128, activation=\"relu\"),\n","    layers.Dense(10, activation=\"softmax\")\n","])\n","\n","# Step 5: Compile model with selected learning rate\n","optimizer = keras.optimizers.Adam(learning_rate=learning_rate)\n","\n","model.compile(\n","    optimizer=optimizer,\n","    loss=\"sparse_categorical_crossentropy\",\n","    metrics=[\"accuracy\"]\n",")\n","\n","# Step 6: Train model using selected batch_size and epochs\n","history = model.fit(\n","    x_train, y_train,\n","    epochs=epochs,\n","    batch_size=batch_size,\n","    validation_split=0.1,\n","    verbose=1\n",")\n","\n","# Step 7: Evaluate on test data\n","test_loss, test_acc = model.evaluate(x_test, y_test, verbose=0)\n","print(\"Test accuracy:\", test_acc)\n","print(\"Used hyperparameters -> lr:\", learning_rate, \", batch_size:\", batch_size, \", epochs:\", epochs)"]}]}
